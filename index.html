<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Goutam Yelluru Gopal</title>

  <meta name="author" content="Goutam Yelluru Gopal">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table
    style="width:100%;max-width:60%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Goutam Yelluru Gopal
                  </p>
                  <p>I am a PhD student at the <a href="http://users.encs.concordia.ca/~amer/vidpro/">VidPro Group</a>,
                    Dept. of Electrical and Computer Engineering, <a href="https://www.concordia.ca/">Concordia
                      University</a>. My main research interest lies at the intersection of Computer Vision and Machine
                    Learning, especially towards designing lightweight, robust algorithms for Visual Object Tracking.
                  </p>
                  <p class="description">
                    I hold an MSc Degree in Computer Science from <a
                      href="https://www.uni-saarland.de/en/home.html">Saarland University</a>, with specialization in
                    Machine Learning. I did my Masters Thesis at the <a
                      href="https://www.ml.uni-saarland.de/index.htm">Machine Learning Group </a> on tackling
                    Algorithmic Bias in binary classifiers.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:goutamyg@gmail.com"> Email</a> &nbsp;/&nbsp;
                    <!-- <a href="https://github.com/leonidk">GitHub</a> &nbsp;/&nbsp; -->
                    <a href="https://scholar.google.co.in/citations?user=3n9IoT8AAAAJ&hl=en">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://github.com/goutamyg">Github</a>
                    &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/goutam-yelluru-gopal-93549428/"> LinkedIn </a>
                    &nbsp;/&nbsp;
                    <a href="https://drive.google.com/file/d/1XMXDc0gYJLZVb3-IqsAhU0jG19b2jQHy/view?usp=drive_link">CV</a>
                   

                  </p>
                </td>

                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/Goutam.png"><img style="width:100%;max-width:70%" alt="profile photo"
                      src="images/Goutam.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>News</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <tr>
                <ul>
                  
                  <li><b>Starting April 2024, I am looking for summer interships or full-time positions in industry.</b> Feel free to  <a href="https://www.linkedin.com/in/goutam-yelluru-gopal-93549428/">connect</a>  </li> <br/>
                  <li>11/2023: Presented my recent research work at BMVC2023<a href="https://bmvc2023.org/authors/doctoral-consortium/"> Doctoral Consortium</a>. Slides <a href="https://drive.google.com/file/d/1Q-zbqnLBggPpwWExoOEAbCb2f2bqk9ON/view?usp=drive_link">here</a></li>
                  <li>10/2023: I was awarded a <a href="https://bmvc2023.org/attending/student-funding/">grant</a> covering the BMVC2023 conference fees and accommodation costs. Thanks to the organizing committee! </li>
                  <li>10/2023: I was awarded the Concordia Conference and Exposition Allowance to attend BMVC2023. Thank you <a href="https://www.concordia.ca/gradstudies/funding/in-program/conference-exposition-allowance.html">Concordia SGS</a>! </li>
                  <li>08/2023: A <a href="https://arxiv.org/abs/2309.03979">paper</a> got accepted at <a href="https://wacv2024.thecvf.com/">IEEE/CVF WACV 2024</a>.</li>
                  <li>08/2023: A <a href="https://arxiv.org/abs/2309.05829">paper</a> got accepted at <a href="https://bmvc2023.org/">BMVC 2023</a>.</li>
                  <li>07/2023: Found a (possible) bug in Apple's <a href="https://github.com/apple/ml-cvnets">Mobile Vision Transformer</a> code; Created a <a href="https://github.com/apple/ml-cvnets/pull/82">PR</a> to fix it. </li>
                  <li>03/2023: A <a href="https://link.springer.com/article/10.1007/s11042-023-15235-x">journal</a> got accepted at <a href="https://www.springer.com/journal/11042">Springer Multimedia Tools and Applications</a>.</li>                  
                  <li>04/2020: A <a href="https://ieeexplore.ieee.org/abstract/document/9190957">paper</a> got accepted at <a href="https://2020.ieeeicip.org/index.html">IEEE ICIP 2020</a>.</li>
                  <li>01/2020: A <a href="https://ieeexplore.ieee.org/abstract/document/9053333">paper</a> got accepted at <a href="https://2020.ieeeicassp.org/index.html">IEEE ICASSP 2020</a>.</li>
                </ul>
              </tr>


            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in computer vision, machine learning, deep learning, and optimization.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>




              <tr>

                <td style="padding:20px;width:2px;vertical-align:middle"><img src="images/wacv2024-logo.png"
                    style="display:block; width:228px; height:81px; margin-left: -21px;"></td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2309.03979">
                    <span class="papertitle">Separable Self and Mixed Attention Transformers for Efficient Object
                      Tracking</span>
                  </a>
                  <br>
                  <strong>Goutam Yelluru Gopal</strong>,
                  <a href="http://users.encs.concordia.ca/~amer/">Maria Amer</a>,
                  <br>
                  <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2024 <font color="red"><strong></strong>(to appear)</font>
                  <br>
                  <a href="https://arxiv.org/abs/2309.03979">arXiv</a> /
                  <a href="https://github.com/goutamyg/SMAT">code</a>
                  <p class="description">Transformer-based models are under-utilized for tracking due to the computational complexity of their attention blocks. 
                    This paper proposes an efficient self and mixed attention transformer-based architecture for lightweight tracking.
                    Simulations show that our <em><strong>SMAT</strong></em> tracker surpasses the performance of related lightweight trackers 
                    on GOT10k, TrackingNet, LaSOT, NfS30, UAV123, and AVisT datasets, while running at 37 fps on CPU and 158 fps on GPU.</p>

                </td>
              </tr>


              <tr>

                <td style="padding:20px;width:2px;vertical-align:middle"><img src="images/bmvc-logo.png"
                    style="display:block; width:211px; height:93px;"></td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://papers.bmvc2023.org/0800.pdf">
                    <span class="papertitle">Mobile Vision Transformer-based Visual Object Tracking</span>
                  </a>
                  <br>
                  <strong>Goutam Yelluru Gopal</strong>,
                  <a href="http://users.encs.concordia.ca/~amer/">Maria Amer</a>,
                  <br>
                  <em>The 34th British Machine Vision Conference (BMVC)</em>, 2023 <font color="red"><strong></strong>(to appear)</font>
                  <br>
                  <a href="https://papers.bmvc2023.org/0800.pdf">paper</a> /
                  <a href="https://arxiv.org/abs/2309.05829">arXiv</a> /
                  <a href="https://github.com/goutamyg/MVT">code</a> /
                  <a href="https://bmvc2022.mpi-inf.mpg.de/BMVC2023/0800_poster.pdf">poster</a> /
                  <a href="https://bmvc2022.mpi-inf.mpg.de/BMVC2023/0800_video.mp4">video</a>

                  <p class="description">The state-of-the-art Vision Transformer-based trackers are computationally expensive since they have a large number of model 
                    parameters and rely on specialized hardware (e.g., GPU) for faster inference. We propose a
                    lightweight, accurate, and fast tracking algorithm using Mobile Vision Transformers (MobileViT) as
                    the backbone for the first time, along with a novel approach to fuse the template and search
                    region representations in the MobileViT backbone. </p>

                </td>
              </tr>

              <tr>

                <td style="padding:20px;width:2px;vertical-align:middle"><img src="images/MMTA.jpg"
                    style="display:block; width:132px; height:170px; margin-left: 70px;"></td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/article/10.1007/s11042-023-15235-x">
                    <span class="papertitle">Reliable interconnected channels for dynamic DCF based visual
                      tracking</span>
                  </a>
                  <br>
                  <strong>Goutam Yelluru Gopal</strong>,
                  <a href="http://users.encs.concordia.ca/~amer/">Maria Amer</a>,
                  <br>
                  <em>Springer's Multimedia Tools and Application (MTAP)</em>, 2023 &nbsp 
                  <br>

                  <p class="description">
                    In DCF-based trackers, several non-discriminative or unreliable channels display ambiguous filter
                    responses due to the effect of various external factors. We address this problem by
                    proposing a three-fold objective function that accounts for the relationship between channels along
                    with per-channel reliability scores during channel weight learning and a temporal prior. In
                    addition, we present an algorithm to compute channel weights efficiently and maintain the
                    tracking speed.
                  </p>

                </td>
              </tr>







              <tr>


                <td style="padding:20px;width:15%;vertical-align:middle"><img src="images/icip2020_logo.jpg"
                    style="display:block; width:200px; height:200px; margin-left: 40px ;"></td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9190957">
                    <span class="papertitle">Reliable Temporally Consistent Feature Adaptation for Visual Object
                      Tracking</span>
                  </a>

                  <br>
                  <strong>Goutam Yelluru Gopal</strong>, <a href="http://users.encs.concordia.ca/~amer/">Maria Amer</a>
                  <br>
                  <em>27th IEEE International Conference on Image Processing (ICIP)</em>, 2020
                  <br>
                  <p class="description">Use of multiple features and sophisticated learning methods have increased the accuracy
                    of DCF-based tracking results. However, unreliable features lead to erroneous target localization
                    and lead to tracking failures. To alleviate this problem, we propose a method for online adaptation of
                    feature weights based on their reliability. Our objective is modeled as a convex optimization problem for
                    robust learning of feature weights. </p>
                </td>
              </tr>



              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/icassp2020_logo.png"
                    style="display:block; width:235px; height:140px; margin-left: -23px;"></td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9053333">
                    <span class="papertitle">Dynamic Channel Pruning For Correlation Filter Based Object Tracking</span>
                  </a>
                  <br>
                  <strong>Goutam Yelluru Gopal</strong>,
                  <a href="http://users.encs.concordia.ca/~amer/">Maria Amer</a>
                  <br>
                  <em>45th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) </em>, 2020
                  <br>
                  <p class="description">
                    In DCF-based tracking, not all channels contain useful information for target localization. During
                    challenging scenarios, non-discriminative channels lead to erroneous tracker. To mitigate this
                    problem, we propose a method for dynamic channel pruning. The proposed method for learning of
                    channel weights is modeled as a non-smooth convex optimization problem. We also propose an algorithm
                    to solve the resulting problem efficiently compared to off-the-shelf solvers.
                  </p>
                </td>
              </tr>



            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website" style="font-size: 14px;">source
                      code.</a> Do not scrape the HTML from this page itself, as it includes analytics
                    tags that you do not want on your own website use the github code instead.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>